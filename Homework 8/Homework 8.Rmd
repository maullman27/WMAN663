---
title: "Homework8"
author: "MacKenzie Ullman"
date: "4/27/2021"
output: html_document
---

Fit an N-mixture model that assumes abundance is a function of wetland size and type, and detection probability is a function of sky and time. 

```{r}
setwd("F:/Quant Eco")
getwd()
HW8 <- read.csv(file ='sosp_nmix.csv')
head(HW8)
summary(HW8)
HW8 <- read.csv('sosp_nmix.csv')
head(HW8)
```

```{r}
library(unmarked)


sosp_mat <- as.matrix(HW8)
nmix_data <- unmarkedFramePCount(y = sosp_mat)
```

```{r}
#detection covariates
p_covs <- read.csv('p_covs_nmix.csv')
head(p_covs)
```
```{r}
#detection covariates
det_covs <- list(
time = data.frame(p_covs[, c('time.1', 'time.2')]),
sky = data.frame(sky.1 = factor(p_covs$sky.1),
sky.2 = factor(p_covs$sky.2))
)

nmix_data <- unmarkedFramePCount(y = sosp_mat,obsCovs = det_covs)
```

```{r}
#site level covariates
site_covs <- read.csv('n_covs_nmix.csv')
head(site_covs)
```
```{r}
#site level covariates
site_covs$herb <- factor(site_covs$herb)
site_covs$shrub1 <- factor(site_covs$shrub1)
site_covs$bareground <- factor(site_covs$bareground)
site_covs$shrub5 <- factor(site_covs$shrub5)

nmix_data <- unmarkedFramePCount(y = sosp_mat, siteCovs = site_covs, obsCovs = det_covs)

```

```{r}
fit <- pcount(formula = ~ time + sky ~ size + type, data = nmix_data, K = 100)
summary(fit)
```

Write a function that calculates the sum of squared Pearson residuals from a fitted model.
```{r}
# obtaining estimates of psi_i
fitted_psi <- predict(fit, type = 'state')
fitted_psi$Predicted[1]
# obtaining estimates of p_ij
fitted_p <- predict(fit, type = 'det')
fitted_p$Predicted[1]
```
```{r}
# calculating psi_i * p_ij
fitted_psi$Predicted[1] * fitted_p$Predicted[1]
## [1] 0.1903982
# comparing with quantity calculated in unmarked
fitted(fit)[1]
```

```{r}
#expected abundance
new_lam <- data.frame(size = rep(mean(site_covs$size), times = 2),
type = factor(c('acep', 'reference'),
levels = c('acep', 'reference')))

abundprd <- predict(object = fit, newdata = new_lam, type = 'state')

abundprd
#estimated detection probability
new_p <- data.frame(
time = rep(mean(c(p_covs[, 'time.1'], p_covs[, 'time.2'])),times = 4),
sky = factor(c('0', '1', '2', '3'),
levels = c('0', '1', '2', '3'))
)

detprd <- predict(object = fit, newdata = new_p,type = 'det')

detprd

```


```{r}
sspr_func2 <- function(x){sum(residuals(x, type="pearson")^2)}
```

```{r}
sspr <-sum(residuals(fit, type="pearson")^2)
sspr
```
```{r}
#answer
sspr_func2(fit)
```

Function is sspr_func2


Use the parboot() function in R to simulate the distribution of this test statistic under the assumption that your fitted model is the data-generating model. Simulate 1000 values of the test statistic.
```{r}
library(unmarked)
pb <- parboot(fit, sspr_func2, nsim = 1000, report = 1)
```



Plot the distribution of the simulated test statistic. Include in this plot the value of your test statistic calculated from your fitted model. What is the null hypothesis you are testing when conducting model checking? Do you reject or fail to reject this null hypothesis? What are the implications for how well
you model fits the data?
```{r}
hist(pb@t.star[, 1], xlab = 'sspr',
main = 'distribution of test statistic',
cex.axis = 1.5, cex.lab = 1.5, cex.main = 1.5)
lines(x = rep(sspr_func2(fit), 2),
y = c(0, 1000),
col = 'red', lwd = 3)

```
The null hypothesis is that the fitted model is the data-generating model.we reject the null hypothesis. The model does not fit the data well.
